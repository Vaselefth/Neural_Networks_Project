{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworksProject1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMQIqkvJD7HsLhyfwK82st",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaselefth/Neural_Networks_Project/blob/master/NeuralNetworksProject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kredpm4PFeLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "#Load Dataset (magic04data.csv) on Colab\n",
        "\"\"\"\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\"\"\"\n",
        "#Transform csv file to Dataframe with Pandas, for manipulation and check for missing values\n",
        "missing_values = [\"n/a\", \"na\", \"--\",\"null\"]\n",
        "dataframe = pd.read_csv(io.StringIO(uploaded['magic04data.csv'].decode('utf-8')),header=None, na_values = missing_values)\n",
        "dataframe.dropna(how='any')\n",
        "number_of_missing_values = dataframe.isnull().sum().sum()\n",
        "print(\"Missing values in dataset are: \" + str(number_of_missing_values) + \"\\n\")\n",
        "\n",
        "#Replace Classification Values at column 10 with numeric values 0 for \"g\" and 1 for \"h\"\n",
        "dataframe[10].replace({\"g\": 0, \"h\": 1}, inplace=True)\n",
        "\n",
        "#Shuffle Dataset because Classes were ordered \n",
        "df = dataframe.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#Use Data Standardization for every input column with this method {y = (x - mean) / standard_deviation}\n",
        "scaler = StandardScaler()\n",
        "for i in range(10):\n",
        "  df[i] = scaler.fit_transform(df[i].values.reshape(-1,1))\n",
        "\n",
        "#Get some Test Data for later\n",
        "Test_Inputs = []\n",
        "Test_Class = []\n",
        "for i in range(10):\n",
        "  Test_Inputs.append(list(df.iloc[i,:-1]))\n",
        "  Test_Class.append(df.iloc[i, -1])\n",
        "\n",
        "#Drop the previous Test Data from Dataset so that cant be memorized and use only for testing\n",
        "for i in range(10):\n",
        "  df.drop(i,inplace=True)\n",
        "\n",
        "#Split Dataset into Input (X) and Output (y) variables\n",
        "X = df.loc[:, 0:9]\n",
        "y = df.loc[:, 10]\n",
        "\n",
        "#Split into train and test datasets with 1/3 test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "print(\"Final Dataset Used:\" + \"\\n\")\n",
        "print(df)\n",
        "\n",
        "#Define the Neural Network Model \n",
        "model = Sequential()  \n",
        "model.add(Dense(20, input_dim=10, activation='relu'))\n",
        "#model.add(Dense(30, activation='relu'))\n",
        "#model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Compile the Model and calculate accuracy metric\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit the Model and return history object for more details\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "#Evaluate the Model\n",
        "_, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train Accuracy: %.2f, Test_Accuracy: %.2f' % (train_accuracy*100, test_accuracy*100))\n",
        "print(\"\\n\")\n",
        "\n",
        "#Test the Neural Network to new Data\n",
        "Tests = np.array(Test_Inputs) \n",
        "Class = np.array(Test_Class) \n",
        "predictions = model.predict_classes(Tests)\n",
        "print(\"Test examples:\" + \"\\n\")\n",
        "for i in range(10):\n",
        "\tprint('%s => %d (expected %d)' % (Tests[i].tolist(), predictions[i], Class[i]))\n",
        "\n",
        "#Plot loss during training\n",
        "plt.subplot(211)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Test')\n",
        "plt.legend()\n",
        "\n",
        "#Plot accuracy during training\n",
        "plt.subplot(212)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3Gg5B9K6NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}